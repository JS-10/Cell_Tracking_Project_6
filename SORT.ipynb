{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sort.sort import Sort  # pip install sort-tracker or clone from abewley/sort (cloning preferred)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def coco_bbox_to_sort_bbox(center_x, center_y, width, height):\n",
    "    x1 = center_x - width / 2\n",
    "    y1 = center_y - height / 2\n",
    "    x2 = center_x + width / 2\n",
    "    y2 = y1 + height\n",
    "    return [x1, y1, x2, y2]\n"
   ],
   "id": "526bc8a1dff16c99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_DIR = Path(\"dataset_jpg/dataset\")\n",
    "ANN_FILE = DATASET_DIR / \"annotations.json\"\n",
    "\n",
    "MAX_AGE = 30  # 1 to 30, 1 standard\n",
    "MIN_HITS = 3  # 1 to 5, 3 standard\n",
    "IOU_THRESHOLD = 0.3  # 0.0 to 1.0, 3.0 standard\n",
    "\n",
    "with ANN_FILE.open(\"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "annotations = coco_data['annotations']\n",
    "images = coco_data['images']\n",
    "\n",
    "# Build image_id → image_info\n",
    "image_id_to_info = {img['id']: img for img in images}\n",
    "\n",
    "# Group annotations by video_id and then by frame_id\n",
    "video_frames = defaultdict(lambda: defaultdict(list))\n",
    "for ann in annotations:\n",
    "    img_info = image_id_to_info[ann['image_id']]\n",
    "    video_id = ann['video_id']\n",
    "    frame_id = img_info['frame_id']\n",
    "    bbox = ann['bbox']\n",
    "    category_id = ann['category_id']\n",
    "\n",
    "    # Convert [center_x, center_y, w, h] → [x1, y1, x2, y2]\n",
    "    x1, y1, x2, y2 = coco_bbox_to_sort_bbox(*bbox)\n",
    "    video_frames[video_id][frame_id].append([x1, y1, x2, y2, 1.0])  # Confidence = 1.0\n"
   ],
   "id": "96be78dda1e0878c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tracking_results = []  # To hold all frame tracking results\n",
    "\n",
    "for video_id, frames in video_frames.items():\n",
    "    tracker = Sort(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD)\n",
    "    sorted_frames = sorted(frames.items())\n",
    "\n",
    "    for frame_id, detections in sorted_frames:\n",
    "        dets_np = np.array(detections)\n",
    "        tracks = tracker.update(dets_np)\n",
    "\n",
    "        for track in tracks:\n",
    "            x1, y1, x2, y2, track_id = track\n",
    "            tracking_results.append({\n",
    "                'video_id': video_id,\n",
    "                'frame_id': frame_id,\n",
    "                'track_id': int(track_id),\n",
    "                'bbox': [float(x1), float(y1), float(x2 - x1), float(y2 - y1)]\n",
    "            })\n"
   ],
   "id": "3b7fcf05600cc970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "with open('sort_tracking_results.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['video_id', 'frame_id', 'track_id', 'bbox'])\n",
    "    writer.writeheader()\n",
    "    for row in tracking_results:\n",
    "        writer.writerow(row)\n"
   ],
   "id": "502dc3fabfaedd5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "46c940a674fc0734"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_iou_matrix(gt_boxes, pred_boxes):\n",
    "    \"\"\"\n",
    "    Compute an IoU matrix between two sets of boxes.\n",
    "    Each box is [x, y, w, h]\n",
    "    Returns a cost matrix where cost = 1 - IoU (for motmetrics)\n",
    "    \"\"\"\n",
    "    iou_matrix = np.zeros((len(gt_boxes), len(pred_boxes)), dtype=np.float32)\n",
    "\n",
    "    for i, (x1, y1, w1, h1) in enumerate(gt_boxes):\n",
    "        xa1, ya1, xa2, ya2 = x1, y1, x1 + w1, y1 + h1\n",
    "        area_gt = w1 * h1\n",
    "\n",
    "        for j, (x2, y2, w2, h2) in enumerate(pred_boxes):\n",
    "            xb1, yb1, xb2, yb2 = x2, y2, x2 + w2, y2 + h2\n",
    "            area_pred = w2 * h2\n",
    "\n",
    "            # Intersection\n",
    "            inter_x1 = max(xa1, xb1)\n",
    "            inter_y1 = max(ya1, yb1)\n",
    "            inter_x2 = min(xa2, xb2)\n",
    "            inter_y2 = min(ya2, yb2)\n",
    "\n",
    "            inter_w = max(0, inter_x2 - inter_x1)\n",
    "            inter_h = max(0, inter_y2 - inter_y1)\n",
    "            inter_area = inter_w * inter_h\n",
    "\n",
    "            union_area = area_gt + area_pred - inter_area\n",
    "            iou = inter_area / union_area if union_area > 0 else 0.0\n",
    "            iou_matrix[i, j] = 1.0 - iou  # for motmetrics: cost = 1 - IoU\n",
    "\n",
    "    return iou_matrix"
   ],
   "id": "9bb1ddbb6f0663fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sort.sort import Sort\n",
    "import motmetrics as mm\n",
    "\n",
    "# Load your COCO-style explanation.json\n",
    "# with open(\"explanation.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# annotations = coco_data[\"annotations\"]\n",
    "# images = coco_data[\"images\"]\n",
    "videos = coco_data[\"videos\"]\n",
    "\n",
    "# Build index\n",
    "image_by_id = {img[\"id\"]: img for img in images}\n",
    "anns_by_video = defaultdict(list)\n",
    "for ann in annotations:\n",
    "    anns_by_video[ann[\"video_id\"]].append(ann)\n",
    "\n",
    "# Init MOT accumulator\n",
    "mm.lap.default_solver = 'lap'\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "# Process a single video (repeat in loop for all) # ToDo: Make loop over all videos\n",
    "video_id = 1  # iterate from 1 to 274\n",
    "video_anns = anns_by_video[video_id]\n",
    "tracker = Sort()\n",
    "\n",
    "# Group annotations by frame\n",
    "anns_by_frame = defaultdict(list)\n",
    "for ann in video_anns:\n",
    "    img = image_by_id[ann[\"image_id\"]]\n",
    "    anns_by_frame[img[\"frame_id\"]].append(ann)\n",
    "\n",
    "gt_all, pred_all = [], []\n",
    "\n",
    "# Sort by frame_id\n",
    "for frame_id in sorted(anns_by_frame.keys()):\n",
    "    anns = anns_by_frame[frame_id]\n",
    "\n",
    "    # Build detection list for SORT: [x1, y1, x2, y2, conf]\n",
    "    dets = []\n",
    "    gt_ids = []\n",
    "    gt_boxes = []\n",
    "\n",
    "    for ann in anns:\n",
    "        x_center, y_center, w, h = ann[\"bbox\"]\n",
    "        x1, y1 = x_center - w / 2, y_center - h / 2\n",
    "        x2, y2 = x1 + w, y1 + h\n",
    "        dets.append([x1, y1, x2, y2, 1.0])  # dummy conf\n",
    "        gt_ids.append(ann[\"cell_id\"])\n",
    "        gt_boxes.append([x1, y1, w, h])\n",
    "\n",
    "        # Save GT\n",
    "        gt_all.append([frame_id + 1, ann[\"cell_id\"], x1, y1, w, h])  # 1-based frame\n",
    "\n",
    "    dets_np = np.array(dets)\n",
    "    tracks = tracker.update(dets_np)\n",
    "\n",
    "    # Save predictions for motmetrics\n",
    "    # pred_boxes = [trk[\"bbox\"] for trk in tracking_results[(video_id, frame_id)]]\n",
    "    # pred_ids = [trk[\"track_id\"] for trk in tracking_results[(video_id, frame_id)]]\n",
    "    pred_ids = []\n",
    "    pred_boxes = []\n",
    "    for track in tracks:\n",
    "        x1, y1, x2, y2, track_id = track\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        pred_all.append([frame_id + 1, int(track_id), x1, y1, w, h])\n",
    "        pred_ids.append(track_id)\n",
    "        pred_boxes.append([x1, y1, w, h])\n",
    "\n",
    "    # Match predictions to GT using bbox IoU\n",
    "    from motmetrics.utils import iou_matrix\n",
    "\n",
    "    if gt_boxes and pred_boxes:\n",
    "        distances = compute_iou_matrix(gt_boxes, pred_boxes)\n",
    "        distances[distances > (1 - 0.5)] = np.nan  # Apply IoU threshold (max_iou = 0.5)\n",
    "        acc.update(gt_ids, pred_ids, distances)\n",
    "    else:\n",
    "        acc.update(gt_ids, [], np.array([]))  # no pred\n",
    "\n",
    "# Save CSVs (optional)\n",
    "pd.DataFrame(gt_all, columns=[\"frame\", \"id\", \"x\", \"y\", \"w\", \"h\"]).to_csv(\"gt.csv\", index=False)\n",
    "pd.DataFrame(pred_all, columns=[\"frame\", \"id\", \"x\", \"y\", \"w\", \"h\"]).to_csv(\"pred.csv\", index=False)\n",
    "\n",
    "# Evaluate\n",
    "mh = mm.metrics.create()\n",
    "summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name='SORT')\n",
    "print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mm.io.motchallenge_metric_names))\n",
    "# summary = mh.compute(acc, name='SORT')\n",
    "# print(mm.io.render_summary(summary, formatters=mh.formatters))\n",
    "print(f\"Processed {len(gt_all)} frames\")\n"
   ],
   "id": "b0eb6586abe12eae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load annotations\n",
    "# with open(\"explanation.json\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# annotations = data[\"annotations\"]\n",
    "# images = data[\"images\"]\n",
    "image_by_id = {img[\"id\"]: img for img in images}\n",
    "\n",
    "# Map annotations per image\n",
    "from collections import defaultdict\n",
    "anns_by_image = defaultdict(list)\n",
    "for ann in annotations:\n",
    "    anns_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "# Load GT and SORT predictions\n",
    "import pandas as pd\n",
    "gt_df = pd.read_csv(\"gt.csv\")    # columns: frame, id, x, y, w, h\n",
    "pred_df = pd.read_csv(\"pred.csv\")  # same format with SORT track_ids\n",
    "\n",
    "def draw_frame(video_id, frame_id, img_dir=\"dataset_jpg/dataset\"):\n",
    "    # Find image metadata\n",
    "    image_info = next(img for img in images if img[\"video_id\"] == video_id and img[\"frame_id\"] == frame_id)\n",
    "    image_id = image_info[\"id\"]\n",
    "    filename = os.path.join(img_dir, f\"{video_id:03d}/images\", os.path.basename(image_info[\"file_name\"]))\n",
    "\n",
    "    # Load image\n",
    "    img = Image.open(filename).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Load ground truth boxes\n",
    "    for ann in anns_by_image[image_id]:\n",
    "        x_center, y_center, w, h = ann[\"bbox\"]\n",
    "        x1 = x_center - w / 2\n",
    "        y1 = y_center - h / 2\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        category = ann[\"category_id\"]  # 1 = living, 2 = dead\n",
    "        cell_id = ann[\"cell_id\"]\n",
    "\n",
    "        color = \"green\" if category == 1 else \"red\"\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n",
    "        draw.text((x1, y1 - 10), f\"GT:{cell_id}\", fill=color)\n",
    "\n",
    "    # Load SORT predictions\n",
    "    preds = pred_df[pred_df[\"frame\"] == frame_id + 1]  # 1-based in pred.csv\n",
    "    for _, row in preds.iterrows():\n",
    "        x, y, w, h = row[2:6]\n",
    "        x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "        track_id = int(row[\"id\"])\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"blue\", width=2)\n",
    "        draw.text((x1, y2 + 2), f\"SORT:{track_id}\", fill=\"blue\")\n",
    "\n",
    "    # Show image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Video {video_id:03d}, Frame {frame_id}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: Show frame 5 of video 1\n",
    "draw_frame(video_id=1, frame_id=100)"
   ],
   "id": "f50a082344c49799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# NEW VERSION",
   "id": "b54a58c386250f9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sort.sort import Sort\n",
    "import motmetrics as mm\n",
    "\n",
    "DATASET_DIR = Path(\"dataset_jpg/dataset\")\n",
    "ANN_FILE = DATASET_DIR / \"annotations.json\"\n",
    "\n",
    "# === CONFIG ===\n",
    "MAX_AGE = 1\n",
    "MIN_HITS = 3\n",
    "IOU_THRESHOLD = 0.3\n",
    "\n",
    "# === Load Annotations ===\n",
    "with ANN_FILE.open(\"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations = data[\"annotations\"]\n",
    "images = data[\"images\"]\n",
    "image_by_id = {img[\"id\"]: img for img in images}\n",
    "\n",
    "# Group annotations by (video, frame)\n",
    "video_frames = defaultdict(lambda: defaultdict(list))\n",
    "for ann in annotations:\n",
    "    img = image_by_id[ann[\"image_id\"]]\n",
    "    video_id = ann[\"video_id\"]\n",
    "    frame_id = img[\"frame_id\"]\n",
    "\n",
    "    x, y, w, h = ann[\"bbox\"]\n",
    "    x1, y1 = x - w / 2, y - h / 2\n",
    "    x2, y2 = x1 + w, y1 + h\n",
    "    bbox = [x1, y1, x2, y2, 1.0]  # dummy confidence\n",
    "\n",
    "    video_frames[video_id][frame_id].append(bbox)\n",
    "\n",
    "# === Tracking with SORT ===\n",
    "tracking_results = []\n",
    "\n",
    "for video_id, frames in video_frames.items():\n",
    "    tracker = Sort(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD)\n",
    "    sorted_frames = sorted(frames.items())\n",
    "\n",
    "    for frame_id, detections in sorted_frames:\n",
    "        dets_np = np.array(detections)\n",
    "        tracks = tracker.update(dets_np)\n",
    "\n",
    "        for track in tracks:\n",
    "            x1, y1, x2, y2, track_id = track\n",
    "            tracking_results.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"frame_id\": frame_id,\n",
    "                \"track_id\": int(track_id),\n",
    "                \"bbox\": [float(x1), float(y1), float(x2 - x1), float(y2 - y1)]\n",
    "            })\n",
    "\n",
    "# === Organize GT and Predictions for Evaluation ===\n",
    "\n",
    "# Build ground truth per video/frame\n",
    "gt_by_video_frame = defaultdict(list)\n",
    "for ann in annotations:\n",
    "    img = image_by_id[ann[\"image_id\"]]\n",
    "    x, y, w, h = ann[\"bbox\"]\n",
    "    x1, y1 = x - w / 2, y - h / 2\n",
    "    video_id = ann[\"video_id\"]\n",
    "    frame_id = img[\"frame_id\"]\n",
    "    gt_by_video_frame[(video_id, frame_id)].append((ann[\"cell_id\"], [x1, y1, w, h]))\n",
    "\n",
    "# Group predictions\n",
    "pred_by_video_frame = defaultdict(list)\n",
    "for trk in tracking_results:\n",
    "    pred_by_video_frame[(trk[\"video_id\"], trk[\"frame_id\"])].append((trk[\"track_id\"], trk[\"bbox\"]))\n",
    "\n",
    "# === Custom IoU matrix ===\n",
    "def compute_iou_matrix(gt_boxes, pred_boxes):\n",
    "    iou_matrix = np.zeros((len(gt_boxes), len(pred_boxes)), dtype=np.float32)\n",
    "    for i, (x1, y1, w1, h1) in enumerate(gt_boxes):\n",
    "        xa1, ya1, xa2, ya2 = x1, y1, x1 + w1, y1 + h1\n",
    "        area_gt = w1 * h1\n",
    "\n",
    "        for j, (x2, y2, w2, h2) in enumerate(pred_boxes):\n",
    "            xb1, yb1, xb2, yb2 = x2, y2, x2 + w2, y2 + h2\n",
    "            area_pred = w2 * h2\n",
    "\n",
    "            inter_x1 = max(xa1, xb1)\n",
    "            inter_y1 = max(ya1, yb1)\n",
    "            inter_x2 = min(xa2, xb2)\n",
    "            inter_y2 = min(ya2, yb2)\n",
    "\n",
    "            inter_w = max(0, inter_x2 - inter_x1)\n",
    "            inter_h = max(0, inter_y2 - inter_y1)\n",
    "            inter_area = inter_w * inter_h\n",
    "\n",
    "            union = area_gt + area_pred - inter_area\n",
    "            iou = inter_area / union if union > 0 else 0.0\n",
    "            iou_matrix[i, j] = 1.0 - iou  # motmetrics expects cost\n",
    "    return iou_matrix\n",
    "\n",
    "# === MOT Evaluation ===\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "for key in sorted(gt_by_video_frame.keys()):\n",
    "    gt = gt_by_video_frame[key]\n",
    "    pred = pred_by_video_frame.get(key, [])\n",
    "\n",
    "    gt_ids = [g[0] for g in gt]\n",
    "    gt_boxes = [g[1] for g in gt]\n",
    "\n",
    "    pred_ids = [p[0] for p in pred]\n",
    "    pred_boxes = [p[1] for p in pred]\n",
    "\n",
    "    if gt_boxes and pred_boxes:\n",
    "        distances = compute_iou_matrix(gt_boxes, pred_boxes)\n",
    "        distances[distances > (1 - 0.5)] = np.nan  # IoU threshold = 0.5\n",
    "        acc.update(gt_ids, pred_ids, distances)\n",
    "    else:\n",
    "        acc.update(gt_ids, pred_ids, np.empty((len(gt_ids), len(pred_ids))))\n",
    "\n",
    "# === Print Metrics ===\n",
    "mh = mm.metrics.create()\n",
    "summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name=\"SORT\")\n",
    "print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mm.io.motchallenge_metric_names))\n",
    "\n",
    "print(f\"\\n✅ Processed {acc.events['FrameId'].nunique()} frames\")\n"
   ],
   "id": "ee1f29902552ba04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sort.sort import Sort\n",
    "import motmetrics as mm\n",
    "import gc\n",
    "\n",
    "# === SET PARAMETER ===\n",
    "DATASET_DIR = Path(\"D:/Maxi/Cell_Tracking_Project_6/dataset_jpg/dataset\") # path to the dataset\n",
    "ANN_FILE = DATASET_DIR / \"annotations.json\"\n",
    "\n",
    "# === MODEL CONFIG ===\n",
    "MAX_AGE = 1\n",
    "MIN_HITS = 3\n",
    "IOU_THRESHOLD = 0.3\n",
    "\n",
    "# === Folders to Process ===\n",
    "START_FOLDER = 1\n",
    "END_FOLDER = 10\n",
    "\n",
    "\n",
    "# === Custom IoU matrix ===\n",
    "def compute_iou_matrix(gt_boxes, pred_boxes):\n",
    "    iou_matrix = np.zeros((len(gt_boxes), len(pred_boxes)), dtype=np.float32)\n",
    "    for i, (x1, y1, w1, h1) in enumerate(gt_boxes):\n",
    "        # Get the coordinates for the ground truth rectangle\n",
    "        xa1, ya1, xa2, ya2 = x1, y1, x1 + w1, y1 + h1\n",
    "        area_gt = w1 * h1\n",
    "\n",
    "        for j, (x2, y2, w2, h2) in enumerate(pred_boxes):\n",
    "            # Get the coordinates for the prediction rectangle\n",
    "            xb1, yb1, xb2, yb2 = x2, y2, x2 + w2, y2 + h2\n",
    "            area_pred = w2 * h2\n",
    "\n",
    "            # compute coordinates for the area that intersects between ground truth and prediction\n",
    "            inter_x1 = max(xa1, xb1)\n",
    "            inter_y1 = max(ya1, yb1)\n",
    "            inter_x2 = min(xa2, xb2)\n",
    "            inter_y2 = min(ya2, yb2)\n",
    "\n",
    "            inter_w = max(0, inter_x2 - inter_x1)\n",
    "            inter_h = max(0, inter_y2 - inter_y1)\n",
    "            inter_area = inter_w * inter_h\n",
    "\n",
    "            # calculate IoU and output for motmetrics\n",
    "            union = area_gt + area_pred - inter_area\n",
    "            iou = inter_area / union if union > 0 else 0.0\n",
    "            iou_matrix[i, j] = 1.0 - iou  # motmetrics expects cost\n",
    "    return iou_matrix\n",
    "\n",
    "# Initialize MOTAccumulator once\n",
    "acc = mm.MOTAccumulator(auto_id=True) # Keep auto_id=True\n",
    "\n",
    "# === Load Annotations - Optimized Reading (Initial Pass for Mapping) ===\n",
    "print(\"Loading initial annotations for mapping...\")\n",
    "with ANN_FILE.open(\"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations_full = data[\"annotations\"]\n",
    "images = data[\"images\"]\n",
    "image_info_by_id = {img[\"id\"]: (img[\"video_id\"], img[\"frame_id\"]) for img in images}\n",
    "all_video_ids_from_annotations = sorted(list(set(img[\"video_id\"] for img in images)))\n",
    "\n",
    "# Garbage collector\n",
    "del data\n",
    "gc.collect()\n",
    "print(\"Loading completed.\")"
   ],
   "id": "462b727f994c6bbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Filter video_ids based on folder numbers ===\n",
    "video_ids_to_process = []\n",
    "for vid_id in all_video_ids_from_annotations:\n",
    "    try:\n",
    "        vid_num = int(vid_id)\n",
    "        if START_FOLDER <= vid_num <= END_FOLDER:\n",
    "             video_ids_to_process.append(vid_id)\n",
    "    except ValueError:\n",
    "        print(f\"Skipping video_id '{vid_id}' as it's not a numeric ID for folder filtering.\")\n",
    "        continue\n",
    "\n",
    "print(f\"Total videos to process based on folder selection: {len(video_ids_to_process)}\")\n",
    "\n",
    "\n",
    "for video_idx, video_id in enumerate(video_ids_to_process):\n",
    "    print(f\"Processing video {video_idx + 1}/{len(video_ids_to_process)}: Video ID {video_id}\", end='\\r')\n",
    "\n",
    "    video_annotations_by_frame = defaultdict(list)\n",
    "    video_tracking_results = []\n",
    "\n",
    "    for ann in annotations_full:\n",
    "        img_id = ann[\"image_id\"]\n",
    "        if img_id in image_info_by_id:\n",
    "            vid_id_from_img, frame_id = image_info_by_id[img_id]\n",
    "            if vid_id_from_img == video_id:\n",
    "                x, y, w, h = ann[\"bbox\"]\n",
    "                x1, y1 = x - w / 2, y - h / 2\n",
    "                x2, y2 = x1 + w, y1 + h\n",
    "                bbox_for_sort = [x1, y1, x2, y2, 1.0]\n",
    "                video_annotations_by_frame[frame_id].append({\n",
    "                    \"cell_id\": ann[\"cell_id\"],\n",
    "                    \"bbox_gt\": [x1, y1, w, h],\n",
    "                    \"bbox_sort\": bbox_for_sort\n",
    "                })\n",
    "\n",
    "    tracker = Sort(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD)\n",
    "    sorted_frames = sorted(video_annotations_by_frame.items())\n",
    "\n",
    "    for frame_id, frame_data_list in sorted_frames:\n",
    "        detections_for_sort = np.array([item[\"bbox_sort\"] for item in frame_data_list])\n",
    "        if detections_for_sort.size > 0:\n",
    "            tracks = tracker.update(detections_for_sort)\n",
    "\n",
    "            for track in tracks:\n",
    "                x1, y1, x2, y2, track_id = track\n",
    "                video_tracking_results.append({\n",
    "                    \"frame_id\": frame_id,\n",
    "                    \"track_id\": int(track_id),\n",
    "                    \"bbox\": [float(x1), float(y1), float(x2 - x1), float(y2 - y1)]\n",
    "                })\n",
    "\n",
    "    gt_by_frame = defaultdict(list)\n",
    "    for frame_id, frame_data_list in video_annotations_by_frame.items():\n",
    "        for ann_item in frame_data_list:\n",
    "            gt_by_frame[frame_id].append((ann_item[\"cell_id\"], ann_item[\"bbox_gt\"]))\n",
    "\n",
    "    pred_by_frame = defaultdict(list)\n",
    "    for trk in video_tracking_results:\n",
    "        pred_by_frame[trk[\"frame_id\"]].append((trk[\"track_id\"], trk[\"bbox\"]))\n",
    "\n",
    "    all_frames_in_video = sorted(list(set(list(gt_by_frame.keys()) + list(pred_by_frame.keys()))))\n",
    "\n",
    "    for frame_id in all_frames_in_video:\n",
    "        gt = gt_by_frame.get(frame_id, [])\n",
    "        pred = pred_by_frame.get(frame_id, [])\n",
    "\n",
    "        gt_ids = [g[0] for g in gt]\n",
    "        gt_boxes = [g[1] for g in gt]\n",
    "\n",
    "        pred_ids = [p[0] for p in pred]\n",
    "        pred_boxes = [p[1] for p in pred]\n",
    "\n",
    "        if gt_boxes or pred_boxes:\n",
    "            if gt_boxes and pred_boxes:\n",
    "                distances = compute_iou_matrix(gt_boxes, pred_boxes)\n",
    "                distances[distances > (1 - 0.5)] = np.nan\n",
    "                acc.update(gt_ids, pred_ids, distances)\n",
    "            else:\n",
    "                acc.update(gt_ids, pred_ids, np.empty((len(gt_ids), len(pred_ids))))\n",
    "\n",
    "    # Garbage collector\n",
    "    del video_annotations_by_frame\n",
    "    del video_tracking_results\n",
    "    del gt_by_frame\n",
    "    del pred_by_frame\n",
    "    gc.collect()\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(\"\\n--- Final Metrics --------------------------------------------------------------------\")\n",
    "mh = mm.metrics.create()\n",
    "summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name=\"SORT\")\n",
    "print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mm.io.motchallenge_metric_names))\n",
    "print(\"----------------------------------------------------------------------------------------\")"
   ],
   "id": "7ef878b03ba81dc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sort.sort import Sort\n",
    "import motmetrics as mm\n",
    "import gc\n",
    "\n",
    "DATASET_DIR = Path(\"D:/Maxi/Cell_Tracking_Project_6/dataset_jpg/dataset\")\n",
    "ANN_FILE = DATASET_DIR / \"annotations.json\"\n",
    "\n",
    "# === Custom IoU matrix (remains the same) ===\n",
    "def compute_iou_matrix(gt_boxes, pred_boxes):\n",
    "    iou_matrix = np.zeros((len(gt_boxes), len(pred_boxes)), dtype=np.float32)\n",
    "    for i, (x1, y1, w1, h1) in enumerate(gt_boxes):\n",
    "        xa1, ya1, xa2, ya2 = x1, y1, x1 + w1, y1 + h1\n",
    "        area_gt = w1 * h1\n",
    "\n",
    "        for j, (x2, y2, w2, h2) in enumerate(pred_boxes):\n",
    "            xb1, yb1, xb2, yb2 = x2, y2, x2 + w2, y2 + h2\n",
    "            area_pred = w2 * h2\n",
    "\n",
    "            inter_x1 = max(xa1, xb1)\n",
    "            inter_y1 = max(ya1, yb1)\n",
    "            inter_x2 = min(xa2, xb2)\n",
    "            inter_y2 = min(ya2, yb2)\n",
    "\n",
    "            inter_w = max(0, inter_x2 - inter_x1)\n",
    "            inter_h = max(0, inter_y2 - inter_y1)\n",
    "            inter_area = inter_w * inter_h\n",
    "\n",
    "            union = area_gt + area_pred - inter_area\n",
    "            iou = inter_area / union if union > 0 else 0.0\n",
    "            iou_matrix[i, j] = 1.0 - iou\n",
    "    return iou_matrix\n",
    "\n",
    "# === Main processing function ===\n",
    "def run_tracking_and_evaluation(params, annotations_full, image_info_by_id, all_video_ids_from_annotations):\n",
    "    \"\"\"\n",
    "    Runs the SORT tracking and motmetrics evaluation with given parameters.\n",
    "\n",
    "    Args:\n",
    "        params (dict): A dictionary containing 'name', 'MAX_AGE', 'MIN_HITS', 'IOU_THRESHOLD',\n",
    "                       'START_FOLDER', 'END_FOLDER'.\n",
    "        annotations_full (list): All annotations loaded from the JSON file.\n",
    "        image_info_by_id (dict): Mapping from image_id to (video_id, frame_id).\n",
    "        all_video_ids_from_annotations (list): List of all unique video IDs from annotations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (summary_df, name_of_run, total_processed_frames)\n",
    "               summary_df: motmetrics summary DataFrame\n",
    "               name_of_run: Name of the current parameter set\n",
    "               total_processed_frames: Number of unique frames processed\n",
    "    \"\"\"\n",
    "\n",
    "    name_of_run = params['name']\n",
    "    MAX_AGE = params['MAX_AGE']\n",
    "    MIN_HITS = params['MIN_HITS']\n",
    "    IOU_THRESHOLD = params['IOU_THRESHOLD']\n",
    "    START_FOLDER = params['START_FOLDER']\n",
    "    END_FOLDER = params['END_FOLDER']\n",
    "\n",
    "    print(f\"\\n--- Starting run: {name_of_run} ---\")\n",
    "    print(f\"Parameters: MAX_AGE={MAX_AGE}, MIN_HITS={MIN_HITS}, IOU_THRESHOLD={IOU_THRESHOLD}\")\n",
    "    print(f\"Folders: {START_FOLDER} to {END_FOLDER}\")\n",
    "\n",
    "    acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "    video_ids_to_process = []\n",
    "    for vid_id in all_video_ids_from_annotations:\n",
    "        try:\n",
    "            vid_num = int(vid_id)\n",
    "            if START_FOLDER <= vid_num <= END_FOLDER:\n",
    "                 video_ids_to_process.append(vid_id)\n",
    "        except ValueError:\n",
    "            # print(f\"Skipping video_id '{vid_id}' as it's not a numeric ID for folder filtering.\")\n",
    "            continue # Suppress this print for multiple runs to avoid clutter\n",
    "\n",
    "    print(f\"Total videos to process for this run: {len(video_ids_to_process)}\")\n",
    "\n",
    "    total_processed_frames = 0 # initialize counter to keep track of total frames\n",
    "\n",
    "    for video_idx, video_id in enumerate(video_ids_to_process):\n",
    "        # print(f\"Processing video {video_idx + 1}/{len(video_ids_to_process)}: Video ID {video_id}\") # Too verbose for multiple runs\n",
    "\n",
    "        video_annotations_by_frame = defaultdict(list)\n",
    "        video_tracking_results = []\n",
    "\n",
    "        for ann in annotations_full:\n",
    "            img_id = ann[\"image_id\"]\n",
    "            if img_id in image_info_by_id:\n",
    "                vid_id_from_img, frame_id = image_info_by_id[img_id]\n",
    "                if vid_id_from_img == video_id:\n",
    "                    x, y, w, h = ann[\"bbox\"]\n",
    "                    x1, y1 = x - w / 2, y - h / 2\n",
    "                    x2, y2 = x1 + w, y1 + h\n",
    "                    bbox_for_sort = [x1, y1, x2, y2, 1.0]\n",
    "                    video_annotations_by_frame[frame_id].append({\n",
    "                        \"cell_id\": ann[\"cell_id\"],\n",
    "                        \"bbox_gt\": [x1, y1, w, h],\n",
    "                        \"bbox_sort\": bbox_for_sort\n",
    "                    })\n",
    "\n",
    "        tracker = Sort(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD)\n",
    "        sorted_frames = sorted(video_annotations_by_frame.items())\n",
    "\n",
    "        for frame_id, frame_data_list in sorted_frames:\n",
    "            detections_for_sort = np.array([item[\"bbox_sort\"] for item in frame_data_list])\n",
    "            if detections_for_sort.size > 0:\n",
    "                tracks = tracker.update(detections_for_sort)\n",
    "\n",
    "                for track in tracks:\n",
    "                    x1, y1, x2, y2, track_id = track\n",
    "                    video_tracking_results.append({\n",
    "                        \"frame_id\": frame_id,\n",
    "                        \"track_id\": int(track_id),\n",
    "                        \"bbox\": [float(x1), float(y1), float(x2 - x1), float(y2 - y1)]\n",
    "                    })\n",
    "\n",
    "        gt_by_frame = defaultdict(list)\n",
    "        for frame_id, frame_data_list in video_annotations_by_frame.items():\n",
    "            for ann_item in frame_data_list:\n",
    "                gt_by_frame[frame_id].append((ann_item[\"cell_id\"], ann_item[\"bbox_gt\"]))\n",
    "\n",
    "        pred_by_frame = defaultdict(list)\n",
    "        for trk in video_tracking_results: # This was the corrected line.\n",
    "            pred_by_frame[trk[\"frame_id\"]].append((trk[\"track_id\"], trk[\"bbox\"]))\n",
    "\n",
    "        all_frames_in_video = sorted(list(set(list(gt_by_frame.keys()) + list(pred_by_frame.keys()))))\n",
    "\n",
    "        for frame_id in all_frames_in_video:\n",
    "            gt = gt_by_frame.get(frame_id, [])\n",
    "            pred = pred_by_frame.get(frame_id, [])\n",
    "\n",
    "            gt_ids = [g[0] for g in gt]\n",
    "            gt_boxes = [g[1] for g in gt]\n",
    "\n",
    "            pred_ids = [p[0] for p in pred]\n",
    "            pred_boxes = [p[1] for p in pred]\n",
    "\n",
    "            if gt_boxes or pred_boxes:\n",
    "                if gt_boxes and pred_boxes:\n",
    "                    distances = compute_iou_matrix(gt_boxes, pred_boxes)\n",
    "                    distances[distances > (1 - 0.5)] = np.nan\n",
    "                    acc.update(gt_ids, pred_ids, distances)\n",
    "                else:\n",
    "                    acc.update(gt_ids, pred_ids, np.empty((len(gt_ids), len(pred_ids))))\n",
    "                total_processed_frames += 1\n",
    "\n",
    "        del video_annotations_by_frame\n",
    "        del video_tracking_results\n",
    "        del gt_by_frame\n",
    "        del pred_by_frame\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"--- Finished processing videos for {name_of_run} ---\")\n",
    "\n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name=name_of_run)\n",
    "\n",
    "    print(f\"✅ Run {name_of_run}: Processed {total_processed_frames} frames.\")\n",
    "\n",
    "    return summary, name_of_run, total_processed_frames\n",
    "\n",
    "# === Load Annotations (once) ===\n",
    "print(\"Loading initial annotations for mapping (once for all runs)...\")\n",
    "with ANN_FILE.open(\"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations_full = data[\"annotations\"]\n",
    "images = data[\"images\"]\n",
    "image_info_by_id = {img[\"id\"]: (img[\"video_id\"], img[\"frame_id\"]) for img in images}\n",
    "all_video_ids_from_annotations = sorted(list(set(img[\"video_id\"] for img in images)))\n",
    "\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "# === Define multiple parameter sets ===\n",
    "parameter_sets = [\n",
    "    {\n",
    "        'name': 'Default_Params_Folders_1_10',\n",
    "        'MAX_AGE': 1,\n",
    "        'MIN_HITS': 3,\n",
    "        'IOU_THRESHOLD': 0.3,\n",
    "        'START_FOLDER': 1,\n",
    "        'END_FOLDER': 10\n",
    "    },\n",
    "    {\n",
    "        'name': 'Relaxed_IOU_Folders_1_10',\n",
    "        'MAX_AGE': 1,\n",
    "        'MIN_HITS': 3,\n",
    "        'IOU_THRESHOLD': 0.5, # Increased IOU threshold (more relaxed for association)\n",
    "        'START_FOLDER': 1,\n",
    "        'END_FOLDER': 10\n",
    "    },\n",
    "    {\n",
    "        'name': 'HigherMinHits_Folders_1_10',\n",
    "        'MAX_AGE': 1,\n",
    "        'MIN_HITS': 5, # Higher min hits for confirmed track\n",
    "        'IOU_THRESHOLD': 0.3,\n",
    "        'START_FOLDER': 1,\n",
    "        'END_FOLDER': 10\n",
    "    },\n",
    "    {\n",
    "        'name': 'Different_Folders_11_20',\n",
    "        'MAX_AGE': 1,\n",
    "        'MIN_HITS': 3,\n",
    "        'IOU_THRESHOLD': 0.3,\n",
    "        'START_FOLDER': 11, # Different set of folders\n",
    "        'END_FOLDER': 20\n",
    "    }\n",
    "]\n",
    "\n",
    "# === Run all parameter sets and store results ===\n",
    "all_results_summaries = {}\n",
    "all_processed_frames_counts = {}\n",
    "\n",
    "for params in parameter_sets:\n",
    "    summary_df, run_name, processed_frames = run_tracking_and_evaluation(\n",
    "        params, annotations_full, image_info_by_id, all_video_ids_from_annotations\n",
    "    )\n",
    "    all_results_summaries[run_name] = summary_df\n",
    "    all_processed_frames_counts[run_name] = processed_frames\n",
    "\n",
    "    # Optionally, clear tracker's internal state if not explicitly done by creating new object\n",
    "    # (SORT already creates a new tracker per video, so this is about global state if any)\n",
    "    gc.collect() # Force garbage collection between runs to free up memory from the previous run\n",
    "\n",
    "# === Print all stored summaries ===\n",
    "print(\"\\n=== All Run Summaries ===\")\n",
    "for run_name, summary_df in all_results_summaries.items():\n",
    "    print(f\"\\n--- Summary for: {run_name} ---\")\n",
    "    print(mm.io.render_summary(summary_df, formatters=mm.metrics.create().formatters, namemap=mm.io.motchallenge_metric_names))\n",
    "    print(f\"Total frames processed for this run: {all_processed_frames_counts[run_name]}\")\n",
    "\n",
    "print(\"\\n--- All Done! ---\")"
   ],
   "id": "fd497841743aaef5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T16:55:35.589105Z",
     "start_time": "2025-07-10T16:55:10.675360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sort.sort import Sort\n",
    "import motmetrics as mm\n",
    "import gc\n",
    "\n",
    "DATASET_DIR = Path(\"D:/Maxi/Cell_Tracking_Project_6/dataset_jpg/dataset\")\n",
    "ANN_FILE = DATASET_DIR / \"annotations.json\"\n",
    "\n",
    "# === Custom IoU matrix (remains the same) ===\n",
    "def compute_iou_matrix(gt_boxes, pred_boxes):\n",
    "    iou_matrix = np.zeros((len(gt_boxes), len(pred_boxes)), dtype=np.float32)\n",
    "    for i, (x1, y1, w1, h1) in enumerate(gt_boxes):\n",
    "        xa1, ya1, xa2, ya2 = x1, y1, x1 + w1, y1 + h1\n",
    "        area_gt = w1 * h1\n",
    "\n",
    "        for j, (x2, y2, w2, h2) in enumerate(pred_boxes):\n",
    "            xb1, yb1, xb2, yb2 = x2, y2, x2 + w2, y2 + h2\n",
    "            area_pred = w2 * h2\n",
    "\n",
    "            inter_x1 = max(xa1, xb1)\n",
    "            inter_y1 = max(ya1, yb1)\n",
    "            inter_x2 = min(xa2, xb2)\n",
    "            inter_y2 = min(ya2, yb2)\n",
    "\n",
    "            inter_w = max(0, inter_x2 - inter_x1)\n",
    "            inter_h = max(0, inter_y2 - inter_y1)\n",
    "            inter_area = inter_w * inter_h\n",
    "\n",
    "            union = area_gt + area_pred - inter_area\n",
    "            iou = inter_area / union if union > 0 else 0.0\n",
    "            iou_matrix[i, j] = 1.0 - iou\n",
    "    return iou_matrix\n",
    "\n",
    "# === Main processing function ===\n",
    "def run_tracking_and_evaluation(params, annotations_full, image_info_by_id, all_video_ids_from_annotations):\n",
    "    \"\"\"\n",
    "    Runs the SORT tracking and motmetrics evaluation with given parameters.\n",
    "\n",
    "    Args:\n",
    "        params (dict): A dictionary containing 'name', 'MAX_AGE', 'MIN_HITS', 'IOU_THRESHOLD',\n",
    "                       'START_FOLDER', 'END_FOLDER'.\n",
    "        annotations_full (list): All annotations loaded from the JSON file.\n",
    "        image_info_by_id (dict): Mapping from image_id to (video_id, frame_id).\n",
    "        all_video_ids_from_annotations (list): List of all unique video IDs from annotations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (acc, name_of_run, total_processed_frames)\n",
    "               acc: The MOTAccumulator object containing all events for this run.\n",
    "               name_of_run: Name of the current parameter set\n",
    "               total_processed_frames: Number of unique frames processed\n",
    "    \"\"\"\n",
    "\n",
    "    name_of_run = params['name']\n",
    "    MAX_AGE = params['MAX_AGE']\n",
    "    MIN_HITS = params['MIN_HITS']\n",
    "    IOU_THRESHOLD = params['IOU_THRESHOLD']\n",
    "    START_FOLDER = params['START_FOLDER']\n",
    "    END_FOLDER = params['END_FOLDER']\n",
    "\n",
    "    print(f\"\\n--- Starting run: {name_of_run} ---\")\n",
    "    print(f\"Parameters: MAX_AGE={MAX_AGE}, MIN_HITS={MIN_HITS}, IOU_THRESHOLD={IOU_THRESHOLD}\")\n",
    "    print(f\"Folders: {START_FOLDER} to {END_FOLDER}\")\n",
    "\n",
    "    acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "    video_ids_to_process = []\n",
    "    for vid_id in all_video_ids_from_annotations:\n",
    "        try:\n",
    "            vid_num = int(vid_id)\n",
    "            if START_FOLDER <= vid_num <= END_FOLDER:\n",
    "                 video_ids_to_process.append(vid_id)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # print(f\"Total videos to process for this run: {len(video_ids_to_process)}\")\n",
    "\n",
    "    total_frames_updated = 0 # Initialize a counter for frames updated\n",
    "\n",
    "    for video_idx, video_id in enumerate(video_ids_to_process):\n",
    "        print(f\"Processing video {video_idx + 1}/{len(video_ids_to_process)}: Video ID {video_id}\", end='\\r')\n",
    "\n",
    "        video_annotations_by_frame = defaultdict(list)\n",
    "        video_tracking_results = []\n",
    "\n",
    "        for ann in annotations_full:\n",
    "            img_id = ann[\"image_id\"]\n",
    "            if img_id in image_info_by_id:\n",
    "                vid_id_from_img, frame_id = image_info_by_id[img_id]\n",
    "                if vid_id_from_img == video_id:\n",
    "                    x, y, w, h = ann[\"bbox\"]\n",
    "                    x1, y1 = x - w / 2, y - h / 2\n",
    "                    x2, y2 = x1 + w, y1 + h\n",
    "                    bbox_for_sort = [x1, y1, x2, y2, 1.0]\n",
    "                    video_annotations_by_frame[frame_id].append({\n",
    "                        \"cell_id\": ann[\"cell_id\"],\n",
    "                        \"bbox_gt\": [x1, y1, w, h],\n",
    "                        \"bbox_sort\": bbox_for_sort\n",
    "                    })\n",
    "\n",
    "        tracker = Sort(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD)\n",
    "        sorted_frames = sorted(video_annotations_by_frame.items())\n",
    "\n",
    "        for frame_id, frame_data_list in sorted_frames:\n",
    "            detections_for_sort = np.array([item[\"bbox_sort\"] for item in frame_data_list])\n",
    "            if detections_for_sort.size > 0:\n",
    "                tracks = tracker.update(detections_for_sort)\n",
    "\n",
    "                for track in tracks:\n",
    "                    x1, y1, x2, y2, track_id = track\n",
    "                    video_tracking_results.append({\n",
    "                        \"frame_id\": frame_id,\n",
    "                        \"track_id\": int(track_id),\n",
    "                        \"bbox\": [float(x1), float(y1), float(x2 - x1), float(y2 - y1)]\n",
    "                    })\n",
    "\n",
    "        gt_by_frame = defaultdict(list)\n",
    "        for frame_id, frame_data_list in video_annotations_by_frame.items():\n",
    "            for ann_item in frame_data_list:\n",
    "                gt_by_frame[frame_id].append((ann_item[\"cell_id\"], ann_item[\"bbox_gt\"]))\n",
    "\n",
    "        pred_by_frame = defaultdict(list)\n",
    "        for trk in video_tracking_results:\n",
    "            pred_by_frame[trk[\"frame_id\"]].append((trk[\"track_id\"], trk[\"bbox\"]))\n",
    "\n",
    "        all_frames_in_video = sorted(list(set(list(gt_by_frame.keys()) + list(pred_by_frame.keys()))))\n",
    "\n",
    "        for frame_id in all_frames_in_video:\n",
    "            gt = gt_by_frame.get(frame_id, [])\n",
    "            pred = pred_by_frame.get(frame_id, [])\n",
    "\n",
    "            gt_ids = [g[0] for g in gt]\n",
    "            gt_boxes = [g[1] for g in gt]\n",
    "\n",
    "            pred_ids = [p[0] for p in pred]\n",
    "            pred_boxes = [p[1] for p in pred]\n",
    "\n",
    "            if gt_boxes or pred_boxes:\n",
    "                if gt_boxes and pred_boxes:\n",
    "                    distances = compute_iou_matrix(gt_boxes, pred_boxes)\n",
    "                    distances[distances > (1 - 0.5)] = np.nan\n",
    "                    acc.update(gt_ids, pred_ids, distances)\n",
    "                else:\n",
    "                    acc.update(gt_ids, pred_ids, np.empty((len(gt_ids), len(pred_ids))))\n",
    "                total_frames_updated += 1\n",
    "\n",
    "    # print(f\"--- Finished processing videos for {name_of_run} ---\")\n",
    "    print(f\"✅ Run {name_of_run}: Processed {total_frames_updated} frames.\")\n",
    "\n",
    "    return acc, name_of_run, total_frames_updated # Return the acc object directly\n",
    "\n",
    "# === Load Annotations (once) ===\n",
    "print(\"Loading initial annotations for mapping (once for all runs)...\")\n",
    "with ANN_FILE.open(\"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations_full = data[\"annotations\"]\n",
    "images = data[\"images\"]\n",
    "image_info_by_id = {img[\"id\"]: (img[\"video_id\"], img[\"frame_id\"]) for img in images}\n",
    "all_video_ids_from_annotations = sorted(list(set(img[\"video_id\"] for img in images)))\n",
    "\n",
    "del data\n",
    "gc.collect()\n",
    "print(\"✅ Finished loading\")"
   ],
   "id": "22b8e817ddc0569e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading initial annotations for mapping (once for all runs)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T17:03:43.265879Z",
     "start_time": "2025-07-10T16:58:51.727875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Define multiple parameter sets ===\n",
    "parameter_sets = [\n",
    "    {\n",
    "        'name': 'Default',\n",
    "        'MAX_AGE': 1,\n",
    "        'MIN_HITS': 3,\n",
    "        'IOU_THRESHOLD': 0.3,\n",
    "        'START_FOLDER': 1,\n",
    "        'END_FOLDER': 50\n",
    "    },\n",
    "    {\n",
    "        'name': 'Relaxed_IOU',\n",
    "        'MAX_AGE': 1,\n",
    "        'MIN_HITS': 3,\n",
    "        'IOU_THRESHOLD': 0.5,\n",
    "        'START_FOLDER': 1,\n",
    "        'END_FOLDER': 50\n",
    "    },\n",
    "    {\n",
    "        'name': 'HigherMinHits',\n",
    "        'MAX_AGE': 1,\n",
    "        'MIN_HITS': 5,\n",
    "        'IOU_THRESHOLD': 0.3,\n",
    "        'START_FOLDER': 1,\n",
    "        'END_FOLDER': 50\n",
    "    },\n",
    "    # {\n",
    "    #     'name': 'Different_Folders',\n",
    "    #     'MAX_AGE': 1,\n",
    "    #     'MIN_HITS': 3,\n",
    "    #     'IOU_THRESHOLD': 0.3,\n",
    "    #     'START_FOLDER': 11,\n",
    "    #     'END_FOLDER': 20\n",
    "    # }\n",
    "]\n",
    "\n",
    "# === Run all parameter sets and store results ===\n",
    "all_accumulators = {} # Storing MOTAccumulator\n",
    "all_processed_frames_counts = {}\n",
    "\n",
    "for params in parameter_sets:\n",
    "    acc_obj, run_name, processed_frames = run_tracking_and_evaluation(\n",
    "        params, annotations_full, image_info_by_id, all_video_ids_from_annotations\n",
    "    )\n",
    "    all_accumulators[run_name] = acc_obj\n",
    "    all_processed_frames_counts[run_name] = processed_frames\n",
    "\n",
    "    # Garbage Collection\n",
    "    gc.collect()\n",
    "\n",
    "# === Print all stored summaries in one go ===\n",
    "print(\"\\n=== Combined All Run Summaries ===\")\n",
    "mh = mm.metrics.create()\n",
    "\n",
    "summary = mh.compute_many(\n",
    "    list(all_accumulators.values()),\n",
    "    metrics=mm.metrics.motchallenge_metrics,\n",
    "    names=list(all_accumulators.keys()),\n",
    "    generate_overall=False\n",
    ")\n",
    "\n",
    "# Add additional info the summary rendering\n",
    "params_df = pd.DataFrame(parameter_sets).set_index('name')\n",
    "params_to_display = ['MAX_AGE', 'MIN_HITS', 'IOU_THRESHOLD', 'START_FOLDER', 'END_FOLDER']\n",
    "params_df_selected = params_df[params_to_display]\n",
    "summary.index.name = 'name'\n",
    "combined_summary = summary.join(params_df_selected)\n",
    "\n",
    "print(mm.io.render_summary(\n",
    "    combined_summary,\n",
    "    formatters=mh.formatters,\n",
    "    namemap=mm.io.motchallenge_metric_names\n",
    "))\n",
    "\n",
    "print(\"\\n--- Total Frames Processed Per Run ---\")\n",
    "total_count = 0\n",
    "for run_name, count in all_processed_frames_counts.items():\n",
    "    print(f\"{run_name}: {count} frames\")\n",
    "    total_count += count\n",
    "print(f\"➡️ TOTAL: {total_count} frames\")"
   ],
   "id": "104a54ead6b4cb6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting run: Default ---\n",
      "Parameters: MAX_AGE=1, MIN_HITS=3, IOU_THRESHOLD=0.3\n",
      "Folders: 1 to 50\n",
      "✅ Run Default: Processed 7500 frames.\n",
      "\n",
      "--- Starting run: Relaxed_IOU ---\n",
      "Parameters: MAX_AGE=1, MIN_HITS=3, IOU_THRESHOLD=0.5\n",
      "Folders: 1 to 50\n",
      "✅ Run Relaxed_IOU: Processed 7500 frames.\n",
      "\n",
      "--- Starting run: HigherMinHits ---\n",
      "Parameters: MAX_AGE=1, MIN_HITS=5, IOU_THRESHOLD=0.3\n",
      "Folders: 1 to 50\n",
      "✅ Run HigherMinHits: Processed 7500 frames.\n",
      "\n",
      "=== Combined All Run Summaries ===\n",
      "              IDF1  IDP  IDR  Rcll   Prcn  GT  MT  PT ML  FP    FN  IDs    FM  MOTA  MOTP IDt  IDa IDm  MAX_AGE  MIN_HITS  IOU_THRESHOLD  START_FOLDER  END_FOLDER\n",
      "name                                                                                                                                                              \n",
      "Default       9.1% 9.6% 8.7% 90.6%  99.7% 245 203  38  4 534 21322 5861  5621 87.8% 0.107 570 5301  42        1         3            0.3             1          50\n",
      "Relaxed_IOU   6.7% 7.5% 6.1% 80.9% 100.0% 245  88 149  8   3 43237 8832  8935 77.1% 0.085 146 8660   8        1         3            0.5             1          50\n",
      "HigherMinHits 9.1% 9.8% 8.5% 86.5%  99.7% 245 174  63  8 497 30680 5284  4971 83.9% 0.107 500 4801  44        1         5            0.3             1          50\n",
      "\n",
      "--- Total Frames Processed Per Run ---\n",
      "Default: 7500 frames\n",
      "Relaxed_IOU: 7500 frames\n",
      "HigherMinHits: 7500 frames\n",
      "\n",
      " TOTAL: 22500 frames\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
